{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one way\n",
    "ip = pd.read_feather('../data/data/features/count/ip.feather').astype('uint32')\n",
    "app = pd.read_feather('../data/data/features/count/app.feather').astype('uint32')\n",
    "os = pd.read_feather('../data/data/features/count/os.feather').astype('uint32')\n",
    "\n",
    "# n-way\n",
    "ip_day_hour = pd.read_feather('../data/data/features/count/ip_day_hour.feather').astype('uint32')\n",
    "ip_app = pd.read_feather('../data/data/features/count/ip_app.feather').astype('uint32')\n",
    "ip_app_os = pd.read_feather('../data/data/features/count/ip_app_os.feather').astype('uint32')\n",
    "ip_device = pd.read_feather('../data/data/features/count/ip_device.feather').astype('uint32')\n",
    "app_channel = pd.read_feather('../data/data/features/count/app_channel.feather').astype('uint32')\n",
    "ip_hour_os = pd.read_feather('../data/data/features/count/ip_hour_os.feather').astype('uint32')\n",
    "ip_hour_app = pd.read_feather('../data/data/features/count/ip_hour_app.feather').astype('uint32')\n",
    "\n",
    "# user count\n",
    "user = pd.read_feather('../data/data/features/count/user_count.feather').astype('uint32')\n",
    "user_app = pd.read_feather('../data/data/features/count/user_app_count.feather').astype('uint32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unique features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_app_unq = pd.read_feather('../data/data/features/unique/ip_app_unq.feather').astype('uint32')\n",
    "ip_channel_unq = pd.read_feather('../data/data/features/unique/ip_channel_unq.feather').astype('uint32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_click_train = pd.read_feather('../data/data/features/next_click/next_click_train.feather')\n",
    "next_click_test = pd.read_feather('../data/data/features/next_click/next_click_test.feather')\n",
    "next_click_train_1 = pd.read_feather('../data/data/features/next_click/next_click_train_1.feather')\n",
    "next_click_test_1 = pd.read_feather('../data/data/features/next_click/next_click_test_1.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_enc_train = pd.read_feather('../data/data/features/running/train_ip.feather')\n",
    "ip_enc_valid = pd.read_feather('../data/data/features/running/valid_ip.feather')\n",
    "ip_enc_test = pd.read_feather('../data/data/features/running/test_ip.feather')\n",
    "\n",
    "ip_app_enc_train = pd.read_feather('../data/data/features/running/train_ip_app.feather')\n",
    "ip_app_enc_valid = pd.read_feather('../data/data/features/running/valid_ip_app.feather')\n",
    "ip_app_enc_test = pd.read_feather('../data/data/features/running/test_ip_app.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_rank = pd.read_feather('../data/data/features/rank/ip.feather')\n",
    "app_channel_rank = pd.read_feather('../data/data/features/rank/app_channel.feather')\n",
    "app_os_rank = pd.read_feather('../data/data/features/rank/app_os.feather')\n",
    "channel_os_rank = pd.read_feather('../data/data/features/rank/channel_os.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_size(data):\n",
    "    for column in list(data.columns):\n",
    "        if data[column].max() <= 250:\n",
    "            data[column] = data[column].astype('uint8')\n",
    "        elif data[column].max() <= 65000 and data[column].min() >= 0:\n",
    "            data[column] = data[column].astype('uint16')\n",
    "    return data\n",
    "    \n",
    "def merge(data, mode='train'):\n",
    "    print('merge starts..', data.shape)\n",
    "    # one way counts\n",
    "    data = data.merge(ip, on='ip')\n",
    "    data = data.merge(os, on='os')\n",
    "    data = data.merge(app, on='app')\n",
    "    data = reduce_size(data)\n",
    "    print('one way merge complete...', data.shape)\n",
    "    # n way counts\n",
    "    data = data.merge(ip_day_hour, on=['ip','day','hour'])\n",
    "    data = data.merge(ip_app, on=['ip','app'])\n",
    "    data = data.merge(ip_app_os, on=['ip','app','os'])\n",
    "    data = data.merge(ip_device, on=['ip','device'])\n",
    "    data = data.merge(app_channel, on=['app','channel'])\n",
    "    data = data.merge(ip_hour_os, on=['ip','hour','os'])\n",
    "    data = data.merge(ip_hour_app, on=['ip','hour','app'])\n",
    "    data = reduce_size(data)\n",
    "    print('n way merge complete...', data.shape)\n",
    "    # unique counts\n",
    "    data = data.merge(ip_app_unq, on=['ip'])\n",
    "    data = data.merge(ip_channel_unq, on=['ip'])\n",
    "    data = reduce_size(data)\n",
    "    # user counts\n",
    "    data = data.merge(user, on=['ip','device','os'])\n",
    "    data = data.merge(user_app, on=['ip','device','os','app'])\n",
    "    data = reduce_size(data)\n",
    "    print('user counts merge complete...', data.shape)\n",
    "    # rank features\n",
    "    data = data.merge(ip_rank, on=['ip'], how='left')\n",
    "    data = data.merge(app_channel_rank, on=['app','channel'], how='left')\n",
    "    data = data.merge(app_os_rank, on=['app','os'], how='left')\n",
    "    data = data.merge(channel_os_rank, on=['channel','os'], how='left')\n",
    "    data = data.fillna(11)\n",
    "    print('rank features merge complete...', data.shape)\n",
    "    # other features\n",
    "    if mode == 'train':\n",
    "        data = data.merge(next_click_train, on='click_id')\n",
    "        data = data.merge(ip_enc_train, on='click_id', how='left')\n",
    "        data = data.merge(ip_app_enc_train, on='click_id', how='left')\n",
    "        data = data.fillna(0)\n",
    "        data = reduce_size(data)\n",
    "        print('other merge complete...', data.shape)\n",
    "    elif mode == 'valid':\n",
    "        data = data.merge(next_click_train, on='click_id')\n",
    "        data = data.merge(ip_enc_valid, on='ip', how='left')\n",
    "        data = data.merge(ip_app_enc_valid, on=['ip','app'], how='left')\n",
    "        data = data.fillna(0)\n",
    "        data = reduce_size(data)\n",
    "        print('other merge complete...', data.shape)\n",
    "    else:\n",
    "        data = data.merge(next_click_test, on='click_id', how='left')\n",
    "        data = data.merge(ip_enc_test, on='ip', how='left')\n",
    "        data = data.merge(ip_app_enc_test, on=['ip','app'], how='left')\n",
    "        data = data.fillna(0)\n",
    "        data = reduce_size(data)\n",
    "        print('other merge complete...', data.shape)\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge starts.. (88734191, 9)\n",
      "one way merge complete... (88734191, 12)\n",
      "n way merge complete... (88734191, 19)\n",
      "user counts merge complete... (88734191, 23)\n",
      "rank features merge complete... (88734191, 27)\n",
      "other merge complete... (88734190, 30)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_feather('../data/data/files/train_data.feather')\n",
    "train_data = merge(train_data)\n",
    "train_data.to_feather('../data/data/model/train_data.feather')\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge starts.. (20895641, 9)\n",
      "one way merge complete... (20895641, 12)\n",
      "n way merge complete... (20895641, 19)\n",
      "user counts merge complete... (20895641, 23)\n",
      "rank features merge complete... (20895641, 27)\n",
      "other merge complete... (20895641, 30)\n"
     ]
    }
   ],
   "source": [
    "valid_data = pd.read_feather('../data/data/files/valid_data.feather')\n",
    "valid_data = merge(valid_data, 'valid')\n",
    "valid_data.to_feather('../data/data/model/valid_data.feather')\n",
    "del valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge starts.. (18790469, 8)\n",
      "one way merge complete... (18790469, 11)\n",
      "n way merge complete... (18790469, 18)\n",
      "user counts merge complete... (18790469, 22)\n",
      "rank features merge complete... (18790469, 26)\n",
      "other merge complete... (18790469, 29)\n"
     ]
    }
   ],
   "source": [
    "score_data = pd.read_feather('../data/data/files/score_data.feather')\n",
    "score_data = merge(score_data,'score')\n",
    "score_data.to_feather('../data/data/model/score_data.feather')\n",
    "del score_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
